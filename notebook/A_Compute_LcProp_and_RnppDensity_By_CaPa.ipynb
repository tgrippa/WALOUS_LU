{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><font size=\"6\">WalOUS project</font></strong></p>\n",
    "\n",
    "<p><strong><font size=\"6\">A_Compute_LcProp_and_RnppDensity_By_CaPa</font></strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WALOUS_LU - Copyright (C) <2020> <Université catholique de Louvain (UCLouvain), Belgique\n",
    "\t\t\t\t\t Université Libre de Bruxelles (ULB), Belgique\n",
    "\t\t\t\t\t Institut Scientifique de Service Public (ISSeP), Belgique\n",
    "\t\t\t\t\t Service Public de Wallonie (SWP), Belgique >\n",
    "\t\t\t\t\t\t \t\t\t\t\t\t\t\n",
    "\t\n",
    "List of the contributors to the development of WALOUS_LU: see LICENSE file.\n",
    "Description and complete License: see LICENSE file.\n",
    "\t\n",
    "This program (WALOUS_LU) is free software:\n",
    "you can redistribute it and/or modify it under the terms of the\n",
    "GNU General Public License as published by the Free Software\n",
    "Foundation, either version 3 of the License, or (at your option)\n",
    "any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program (see COPYING file).  If not,\n",
    "see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "Jupyter Notebook containing the preprocessing steps consisting of: \n",
    "- Computing the proportion and mode of land cover (COSW product) classes for each cadastral parcel (zonal stats).\n",
    "- Creating the raster layer with classes of neighbourhood density and computing mode of neighbourhood density classes for each cadastral parcel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a Javascript section of code for building the Jupyter notebook's table of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add folder with SCR provided belong to this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add local module to the path\n",
    "src = os.path.abspath('../SRC')\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup environment variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please edit the file in `../SRC/config.py`, containing the configuration parameters, according to your own computer setup. The following cell is used to run this file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run ../SRC/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions that setup the environmental variables\n",
    "import environ_variables as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environmental variables\n",
    "envi.setup_environmental_variables() \n",
    "# Display current environment variables of your computer\n",
    "envi.print_environmental_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRASS GIS Python libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "# Import libraries needed to call GRASS using Python\n",
    "import grass.script as gscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function for GRASS GIS mapset checking and launching\n",
    "from grass_database import check_gisdb, check_location, check_mapset, working_mapset, launch_mapset\n",
    "# Import functions for processing time information\n",
    "from processing_time import start_processing, print_processing_time\n",
    "# Import function that check and create folder\n",
    "from mkdir import check_create_dir\n",
    "# Import function that check if GRASS GIS add-on is installed and install it if needed\n",
    "from gextension import check_install_addon\n",
    "# Import function for importation of r.zonal.classes csv output into a GRASS GIS table\n",
    "from grass_processing import rzonalclasses_sql_insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and create folder if needed\n",
    "check_create_dir(config_parameters['outputfolder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute proportion of LC classes in cadastral blocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import land cover (raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapset \n",
    "start_import = start_processing()\n",
    "launch_mapset(\"FUSIONS\")\n",
    "\n",
    "# Create a list of paths to files with a specific name prefix\n",
    "list_file = glob.glob(os.path.join(data['landcover_folder'][1],\"ocsol2018final_simplified_31370*.tif\"))\n",
    "print(\"There are %s .tif files in the folder\"%len(list_file))\n",
    "\n",
    "# Create a list of tuple with GRASS GIS layer name for raster and their path in the computer drive \n",
    "list_of_lc_raster = []\n",
    "[list_of_lc_raster.append((os.path.splitext(a)[0].split(os.sep)[-1],a)) for a in list_file]\n",
    "\n",
    "# Import individual rasters (for each tile)\n",
    "print(\"Importation of %s files...\"%len(list_file))\n",
    "for rast in list_of_lc_raster:\n",
    "    gscript.run_command('r.in.gdal', overwrite=True, input=rast[1] , output=rast[0])\n",
    "\n",
    "# If mutliple files, create virtual raster, else (single file) rename it.\n",
    "if len(list_file) > 1:\n",
    "    print(\"Creation of VRT\")\n",
    "    gscript.run_command('r.buildvrt', overwrite=True, \n",
    "                        input=\",\".join([a[0] for a in list_of_lc_raster]), \n",
    "                        output=data['landcover_folder'][0])\n",
    "else: \n",
    "    print(\"Rename input raster\")\n",
    "    gscript.run_command('g.rename', overwrite=True, \n",
    "                            raster=\"%s,%s\"%(list_of_lc_raster[0][0],data['landcover_folder'][0]))\n",
    "    \n",
    "# Apply color\n",
    "gscript.run_command('r.colors', map=data['landcover_folder'][0], rules=data['color_file'])\n",
    "print_processing_time(start_import, \"Import achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import cadastral blocs (vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and launch mapset \n",
    "launch_mapset(\"CAPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import vector\n",
    "start_import = start_processing()\n",
    "gscript.run_command('v.import', overwrite=True, input=data['capa'][1], output=data['capa'][0])\n",
    "print_processing_time(start_import, \"Import achieved in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterize cadastral blocs\n",
    "start = start_processing()\n",
    "gscript.run_command('g.mapsets', mapset='FUSIONS', operation='add')\n",
    "gscript.run_command('g.region', vector=data['capa'][0], align=data['landcover_folder'][0])\n",
    "gscript.run_command('v.to.rast', overwrite=True, input=data['capa'][0], output=data['capa'][0],\n",
    "                    use='cat', memory=10000)\n",
    "print_processing_time(start, \"Rasterisation achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute LC proportion by CaPa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if add-on is already installed in the computer and install it not yet installed\n",
    "check_install_addon(\"r.zonal.classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Compute LC class proportions in cadastral plots\n",
    "# Create mapset \n",
    "start = start_processing()\n",
    "launch_mapset(\"CAPA\")\n",
    "gscript.run_command('g.mapsets', quiet=True, mapset='FUSIONS', operation='add')\n",
    "gscript.run_command('g.region', raster=data['capa'][0], align=data['landcover_folder'][0])\n",
    "# Compute LC proportions\n",
    "tmp_csv = \"%s_rzonalclasses\"%gscript.tempfile() # Path to temporary file output\n",
    "ouput_csv = data['lc_capa'][1]\n",
    "gscript.run_command('r.zonal.classes', overwrite=True, zone_map=data['capa'][0], \n",
    "                    raster=data['landcover_folder'][0], prefix='lc', csvfile=tmp_csv)\n",
    "print_processing_time(start, \"Proportions of LC computed in achieved in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the csv output of r.zonal.classes in GRASS SQlite database\n",
    "start_import = start_processing()\n",
    "# Load csv content in python dictionnary\n",
    "incsv = open(tmp_csv, 'r')\n",
    "reader = csv.reader(incsv, delimiter='|')\n",
    "header = next(reader)\n",
    "value_dict = {row[0]:row[1:] for row in reader}\n",
    "incsv.close()\n",
    "# Insert SQL\n",
    "table_name = \"lc_prop\"\n",
    "rzonalclasses_sql_insert(table_name, header, value_dict, overwrite=True)\n",
    "\n",
    "### Table 'capa_with_prop'\n",
    "table_name = \"capa_with_prop\"\n",
    "sql_query = gscript.tempfile()\n",
    "fsql = open(sql_query, 'w')\n",
    "fsql.write('BEGIN TRANSACTION;\\n')\n",
    "if gscript.db_table_exist(table_name):\n",
    "        fsql.write('DROP TABLE %s;\\n'%table_name)\n",
    "create_statement = 'CREATE TABLE %s AS '%table_name\n",
    "create_statement += 'SELECT a.CAPAKEY, b.* FROM capa AS a '\n",
    "create_statement += 'JOIN lc_prop AS b ON a.cat=b.cat;\\n'\n",
    "fsql.write(create_statement)\n",
    "fsql.write('END TRANSACTION;')\n",
    "fsql.close()\n",
    "gscript.run_command('db.execute', input=sql_query, quiet=True)\n",
    "# Export to csv\n",
    "if not os.path.exists(os.path.split(data['lc_capa'][1])[0]):\n",
    "    os.makedirs(os.path.split(data['lc_capa'][1])[0])    \n",
    "gscript.run_command('db.select', overwrite=True, sql=\"SELECT * FROM %s\"%table_name,\n",
    "                    output=data['lc_capa'][1])\n",
    "print_processing_time(start_import, \"Computation of LC classes proportions achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute population density on a 200m surrounding buffer (10 meters spatial resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import RNPP population points (vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapset \n",
    "launch_mapset(\"RNPP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import vector\n",
    "start_import = start_processing()\n",
    "gscript.run_command('v.import', overwrite=True, input=data['rnpp'][1], output=data['rnpp'][0])\n",
    "print_processing_time(start_import, \"Import achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute raster of sum of population on a 200m surrounding neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "raster_resolution = 10\n",
    "buffer_diameter = 400\n",
    "attrib_column = 'MS_POPULAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create mapset \n",
    "launch_mapset(\"POP_DENSITY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give access to other mapsets\n",
    "gscript.run_command('g.mapsets', quiet=True, mapset='RNPP', operation='add')\n",
    "# Define computational region\n",
    "gscript.run_command('g.region', flags='ap', vector=data['rnpp'][0], res=raster_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute v.neighbors.stats\n",
    "start_import = start_processing()\n",
    "gscript.run_command('v.neighbors.stats', overwrite=True, input=data['rnpp'][0], output='rnpp_popsum', method='sum', \n",
    "                    size=buffer_diameter, points_column=attrib_column)\n",
    "print_processing_time(start_import, \"Processing achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reclass into 4 population density classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclassify into density classes\n",
    "start_import = start_processing()\n",
    "formula = \"density_classes=if(isnull(rnpp_popsum),0,if(rnpp_popsum<80,1,if(rnpp_popsum<250,2,if(rnpp_popsum<500,3,4))))\"\n",
    "gscript.mapcalc(formula, overwrite=True)\n",
    "print_processing_time(start_import, \"Processing achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tiff to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"%s_res_%sm_neighbor_%sm.tif\"%(data['rnpp'][0],raster_resolution,int(buffer_diameter/2))\n",
    "export_path = os.path.join(os.path.split(data['rnpp_neighbor'][1])[0],file_name)\n",
    "print(\"Tiff file will be saved on the following location: %s\"%export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute v.neighbors.stats\n",
    "start_import = start_processing()\n",
    "gscript.run_command('r.out.gdal', overwrite=True, input='density_classes',\n",
    "                    output=export_path, format='GTiff', createopt='COMPRESS=DEFLATE', overviews='2')\n",
    "print_processing_time(start_import, \"Processing achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute main density class by CaPa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Compute main density class by cadastral plot\n",
    "start = start_processing()\n",
    "launch_mapset(\"CAPA\")\n",
    "gscript.run_command('g.mapsets', quiet=True, mapset='POP_DENSITY', operation='add')\n",
    "# Compute class mode\n",
    "tmp_csv = \"%s_rzonalclasses\"%gscript.tempfile() # Path to temporary file output\n",
    "ouput_csv = data['rnpp_neighbor'][0]\n",
    "gscript.run_command('r.zonal.classes', overwrite=True, zone_map=data['capa'][0], \n",
    "                    raster='density_classes', prefix='rnpp_200m',\n",
    "                    statistics='mode', csvfile=tmp_csv)\n",
    "print_processing_time(start, \"Modal value of density classes computed in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the csv output of r.zonal.classes in GRASS SQlite database\n",
    "start_import = start_processing()\n",
    "# Load csv content in python dictionnary\n",
    "incsv = open(tmp_csv, 'r')\n",
    "reader = csv.reader(incsv, delimiter='|')\n",
    "header = next(reader)\n",
    "value_dict = {row[0]:row[1:] for row in reader}\n",
    "incsv.close()\n",
    "# Insert SQL\n",
    "table_name_1 = \"lc_prop\"\n",
    "SqlInsert(table_name_1, header, value_dict, overwrite=True)\n",
    "\n",
    "### Table 'capa_with_prop'\n",
    "table_name_2 = \"capa_with_prop\"\n",
    "sql_query = gscript.tempfile()\n",
    "fsql = open(sql_query, 'w')\n",
    "fsql.write('BEGIN TRANSACTION;\\n')\n",
    "if gscript.db_table_exist(table_name_2):\n",
    "        fsql.write('DROP TABLE %s;\\n'%table_name_2)\n",
    "create_statement = 'CREATE TABLE %s AS '%table_name_2\n",
    "create_statement += 'SELECT a.CAPAKEY, b.* FROM capa AS a '\n",
    "create_statement += 'JOIN %s AS b ON a.cat=b.cat;\\n'%table_name_1\n",
    "fsql.write(create_statement)\n",
    "fsql.write('END TRANSACTION;')\n",
    "fsql.close()\n",
    "gscript.run_command('db.execute', input=sql_query, quiet=True)\n",
    "# Export to csv\n",
    "if not os.path.exists(os.path.split(data['rnpp_neighbor'][1])[0]):\n",
    "    os.makedirs(os.path.split(data['rnpp_neighbor'][1])[0])    \n",
    "gscript.run_command('db.select', overwrite=True, sql=\"SELECT * FROM %s\"%table_name_2,\n",
    "                    output=data['rnpp_neighbor'][1])\n",
    "print_processing_time(start_import, \"Csv file exported in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
